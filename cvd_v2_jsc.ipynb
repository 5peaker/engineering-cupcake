{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":15282,"databundleVersionId":565187,"sourceType":"competition"}],"dockerImageVersionId":30123,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.042818,"end_time":"2021-09-21T16:12:40.992565","exception":false,"start_time":"2021-09-21T16:12:40.949747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-20T01:31:46.743601Z","iopub.execute_input":"2021-10-20T01:31:46.744708Z","iopub.status.idle":"2021-10-20T01:31:46.789016Z","shell.execute_reply.started":"2021-10-20T01:31:46.744557Z","shell.execute_reply":"2021-10-20T01:31:46.787667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Add, Dense, Activation, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications import ResNet50, MobileNetV2, ResNet101\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, save_img\n\nimport cv2\nimport random\nimport multiprocessing","metadata":{"papermill":{"duration":5.40741,"end_time":"2021-09-21T16:12:46.424555","exception":false,"start_time":"2021-09-21T16:12:41.017145","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-20T01:32:24.381478Z","iopub.execute_input":"2021-10-20T01:32:24.382278Z","iopub.status.idle":"2021-10-20T01:32:31.169416Z","shell.execute_reply.started":"2021-10-20T01:32:24.382177Z","shell.execute_reply":"2021-10-20T01:32:31.168625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! unzip -o /kaggle/input/platesv2/plates.zip","metadata":{"papermill":{"duration":2.161578,"end_time":"2021-09-21T16:12:48.609475","exception":false,"start_time":"2021-09-21T16:12:46.447897","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-16T15:26:40.890109Z","iopub.execute_input":"2021-10-16T15:26:40.890433Z","iopub.status.idle":"2021-10-16T15:26:42.769306Z","shell.execute_reply.started":"2021-10-16T15:26:40.890391Z","shell.execute_reply":"2021-10-16T15:26:42.76815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRANSFORM IMAGES","metadata":{"papermill":{"duration":0.03313,"end_time":"2021-09-21T16:12:48.676236","exception":false,"start_time":"2021-09-21T16:12:48.643106","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# CLEANING\nif (os.path.exists('data_augment')):\n    shutil.rmtree('data_augment')\nif (os.path.exists('data_test')):\n    shutil.rmtree('data_test')\n\n# CREATE DIRECTORY FOR DATA-AUGMENT\nos.makedirs('data_augment/plates/train/cleaned')\nos.makedirs('data_augment/plates/train/dirty')\nos.makedirs('data_augment/valid/plates/train/cleaned')\nos.makedirs('data_augment/valid/plates/train/dirty')\n\n# CREATE DIRECTORY FOR TEST\nos.makedirs('data_test/plates/test')","metadata":{"papermill":{"duration":0.041983,"end_time":"2021-09-21T16:12:48.750971","exception":false,"start_time":"2021-09-21T16:12:48.708988","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-16T15:26:42.771876Z","iopub.execute_input":"2021-10-16T15:26:42.772189Z","iopub.status.idle":"2021-10-16T15:26:42.78093Z","shell.execute_reply.started":"2021-10-16T15:26:42.772148Z","shell.execute_reply":"2021-10-16T15:26:42.779623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 画像加工・生成系関数\n\n\n## 画像標準化\ndef image_standardization(img):\n    return tf.image.per_image_standardization(\n        img\n    )\n\n\n## グレースケール\ndef image_grayscale(img):\n    \n    # PIL型 -> OpenCV型\n    img = np.array(img, dtype=np.uint8)\n    img = img[:, :, ::-1]\n    \n    # グレースケール\n    #img_gray, _ = cv2.decolor(img)\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    # PIL型 を返却\n    return cv2.cvtColor(img_gray, cv2.COLOR_BGR2RGB)\n\n\n## 背景除去\ndef grabCutFirst(img):\n\n    # PIL型 -> OpenCV型\n    img = np.array(img, dtype=np.uint8)\n    img = img[:, :, ::-1]\n    \n    height, width = img.shape[:2]\n    rect = (15, 15, width-30, height-30)\n    \n    mask = np.zeros(img.shape[:2],np.uint8)\n    bgdModel = np.zeros((1,65),np.float64)\n    fgdModel = np.zeros((1,65),np.float64)\n    cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n    output_img = img*mask2[:,:,np.newaxis]   # 背景が[0,0,0]（黒）となる\n\n    # 背景領域の取得\n    background = img - output_img\n\n    # 黒から白に変換\n    background[np.where((background > [0, 0, 0]).all(axis = 2))] = [255, 255, 255]\n\n    # 合成値 + PIL型 を返却\n    return cv2.cvtColor(background + output_img, cv2.COLOR_BGR2RGB)\n\n\n## クロップ関数\ndef crop(img, l):\n\n    img = Image.fromarray(img.astype(np.uint8))\n    \n    # クロップ\n    l2 = l // 2     # クロップしたい大きさの半分\n    w, h = img.size # 画像の横幅と高さ\n    w2 = w // 2     # 横幅の半分\n    h2 = h // 2     # 高さの半分\n    img = img.crop((w2 - l2, h2 - l2, w2 + l2, h2 + l2))\n\n    # リサイズ｜入力サイズに戻す\n    img = img.resize((w, h))\n    \n    return img\n\n\n## 学習画像加工・生成関数\ndef image_transform_for_training(org_image_dir_path, crop_size_list, rotation_range, sum_data_num, valid_data_num):\n    \n    print('START:image_transform_for_training - ' + org_image_dir_path + ' - ' + str(crop_size_list[0]))\n    \n    # ImageDataGenerator インスタンス生成\n    datagen = ImageDataGenerator(\n           rotation_range=rotation_range,\n           width_shift_range=0,\n           height_shift_range=0,\n           shear_range=0,\n           zoom_range=0,\n           horizontal_flip=False,\n           vertical_flip=False)#,\n           #preprocessing_function=image_standardization)\n    \n    i = 0\n    valid_iter = random.sample(range(sum_data_num), int(valid_data_num))\n    for org_image_file_name in os.listdir(org_image_dir_path):\n        \n        root, ext = os.path.splitext(org_image_file_name)\n        if (ext != '.jpg'):\n            continue\n\n        # 学習用・バリデーション用の画像ディレクトリを完全に分ける\n        image_dir_path = org_image_dir_path\n        if (i in valid_iter):\n            image_dir_path = 'valid/' + org_image_dir_path\n\n        #print('image transform for training : ' + org_image_file_name)\n            \n        # 画像ファイルをPIL形式でオープン\n        img = image.load_img(org_image_dir_path + '/' + org_image_file_name)\n        # PIL形式をnumpyのndarray形式に変換\n        img = image.img_to_array(img)\n        # 背景除去\n        x = grabCutFirst(img)\n        # (height, width, 3) -> (1, height, width, 3)\n        x = x.reshape((1,) + x.shape)\n        \n        # 画像生成\n        j = 0\n        for d in datagen.flow(x, batch_size=1):\n            \n            grab_cut_img = grabCutFirst(d[0])\n            \n            for l in crop_size_list:\n                crop_img = image.img_to_array(crop(grab_cut_img, l))\n                #std_img = np.array(image_standardization(crop_img))\n                std_img = crop_img\n                gray_img = image_grayscale(std_img)\n                #gray_img = std_img\n                save_img('data_augment/' + image_dir_path + '/' + root + '_' + str(l) + '_' + str(j * rotation_range) + ext, Image.fromarray(gray_img.astype(np.uint8)))\n            \n            j = j + 1\n            if ((360/rotation_range) <= j):\n                break\n                \n        i = i + 1\n\n    print('START:image_transform_for_training - ' + org_image_dir_path + ' - ' + str(crop_size_list[0]))\n\n\n## テスト画像加工関数\ndef image_transfrom_for_test(org_image_dir_path, crop_size_list):\n    \n    print('START:image_transform_for_test - ' + org_image_dir_path + ' - ' + str(crop_size_list[0]))\n    \n    for org_image_file_name in os.listdir(org_image_dir_path):\n\n        root, ext = os.path.splitext(org_image_file_name)\n        if (ext != '.jpg'):\n            continue\n    \n        #print('image transform for test : ' + org_image_file_name)\n    \n        img = image.load_img(org_image_dir_path + '/' + org_image_file_name)\n        img = image.img_to_array(img)\n        img = grabCutFirst(img) # 背景除去\n        \n        for l in crop_size_list:\n\n            if (os.path.exists('data_test/' + org_image_dir_path + '/' + str(l)) == False):\n                os.makedirs('data_test/' + org_image_dir_path + '/' + str(l))\n\n            crop_img =  image.img_to_array(crop(img, l))\n            #std_img = np.array(image_standardization(crop_img))\n            std_img = crop_img\n            gray_img = image_grayscale(std_img)\n            #gray_img = std_img\n            save_img('data_test/' + org_image_dir_path + '/' + str(l) + '/' + org_image_file_name,Image.fromarray(gray_img.astype(np.uint8)))\n    \n    print('END:image_transform_for_test - ' + org_image_dir_path + ' - ' + str(crop_size_list[0]))","metadata":{"papermill":{"duration":0.052378,"end_time":"2021-09-21T16:12:48.836839","exception":false,"start_time":"2021-09-21T16:12:48.784461","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-16T15:26:42.789334Z","iopub.execute_input":"2021-10-16T15:26:42.789687Z","iopub.status.idle":"2021-10-16T15:26:42.824695Z","shell.execute_reply.started":"2021-10-16T15:26:42.789644Z","shell.execute_reply":"2021-10-16T15:26:42.822913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 加工用のクロップサイズ種類\ncrop_size_training_list = [91, 171, 251]\ncrop_size_test_list = [91, 171, 251]\n\n# 生成用の回転単位角度\nrotation_range = 90","metadata":{"papermill":{"duration":24.976795,"end_time":"2021-09-21T16:13:13.845971","exception":false,"start_time":"2021-09-21T16:12:48.869176","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-16T15:26:42.82598Z","iopub.execute_input":"2021-10-16T15:26:42.826209Z","iopub.status.idle":"2021-10-16T15:26:42.837481Z","shell.execute_reply.started":"2021-10-16T15:26:42.826177Z","shell.execute_reply":"2021-10-16T15:26:42.836804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 加工・生成\nprocesses = []\n## 学習画像加工・生成\nfor l in crop_size_training_list:  \n    processes.append(multiprocessing.Process(target=image_transform_for_training, args=('plates/train/cleaned',[l], rotation_range, 20, 20 * 0.3,)))\n    processes.append(multiprocessing.Process(target=image_transform_for_training, args=('plates/train/dirty',[l], rotation_range, 20, 20 * 0.3,)))\n## テスト画像加工\nfor l in crop_size_test_list:\n    processes.append(multiprocessing.Process(target=image_transfrom_for_test, args=('plates/test',[l],)))\n\n## プロセスの開始\nfor p in processes:\n    p.start()\n\n## プロセス終了まで待つ\nfor p in processes:\n    p.join()  ","metadata":{"execution":{"iopub.status.busy":"2021-10-16T15:26:42.839317Z","iopub.execute_input":"2021-10-16T15:26:42.839636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREPARE FOR LEARNING MODEL","metadata":{"papermill":{"duration":0.033165,"end_time":"2021-09-21T16:13:13.91298","exception":false,"start_time":"2021-09-21T16:13:13.879815","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# 学習回数等\nimage_size = (224, 224)\nbatch_size = 4\nepochs = 30","metadata":{"papermill":{"duration":0.039425,"end_time":"2021-09-21T16:13:13.986164","exception":false,"start_time":"2021-09-21T16:13:13.946739","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習データ・訓練\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    #plates/train\",\n    \"data_augment/plates/train\",\n    #labels='inferred', \n    #label_mode='categorical',\n    #validation_split=0.3,\n    #subset=\"training\",\n    seed=1307,\n    image_size=image_size,\n    batch_size=batch_size,\n)\n\n# 学習データ・バリデーション\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    #plates/train\",\n    \"data_augment/valid/plates/train\",\n    #labels='inferred', \n    #label_mode='categorical',\n    #validation_split=0.3,\n    #subset=\"validation\",\n    seed=1307,\n    image_size=image_size,\n    batch_size=batch_size,\n)","metadata":{"papermill":{"duration":0.372076,"end_time":"2021-09-21T16:13:14.390696","exception":false,"start_time":"2021-09-21T16:13:14.01862","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習データ｜目視確認\nplt.figure(figsize=(20, 20))\nfor images, labels in train_ds.take(1):\n    for i in range(batch_size):\n        ax = plt.subplot(7, 5, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","metadata":{"papermill":{"duration":1.850316,"end_time":"2021-09-21T16:13:16.273809","exception":false,"start_time":"2021-09-21T16:13:14.423493","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# バリデーションデータ｜目視確認\nplt.figure(figsize=(20, 20))\nfor images, labels in val_ds.take(1):\n    for i in range(batch_size):\n        ax = plt.subplot(7, 5, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LEARNING MODEL","metadata":{"papermill":{"duration":0.056004,"end_time":"2021-09-21T16:13:16.386352","exception":false,"start_time":"2021-09-21T16:13:16.330348","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ディープラーニングモデル\ndef get_model():\n    # 転移モデル\n    ## https://keras.io/ja/applications/#resnet50\n    input_shape = image_size + (3,)\n    model_res = ResNet101(include_top=False, input_shape=input_shape, weights='imagenet')\n    \n    # 追加レイヤー\n    x = model_res.output\n    \n    x = Flatten()(x)\n\n    x = Dense(256)(x)\n    x = Activation('relu')(x)\n    x = Dropout(.5)(x)\n    \n    x = Dense(256)(x)\n    x = Activation('relu')(x)\n    x = Dropout(.5)(x)\n    \n    x = Dense(128)(x)\n    x = Activation('relu')(x)\n    x = Dropout(.5)(x)\n\n    x = Dense(1)(x)\n    \n    outputs = Activation('sigmoid')(x)\n\n    # 転移モデルの学習はしない\n    # 追加した層以外はフリーズする。(パラメータ更新しない)\n    for l in model_res.layers[1:]:\n        l.trainable = False\n    \n    # 合成｜転移モデル + 追加レイヤー\n    model = Model(model_res.input, outputs)\n    \n    return model","metadata":{"papermill":{"duration":0.066747,"end_time":"2021-09-21T16:13:16.508057","exception":false,"start_time":"2021-09-21T16:13:16.44131","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# モデルインスタンス | 同じモデル内容でアンサンブル学習実施\nmodels = {}\nmodels[0] = get_model()\nmodels[1] = get_model()\nmodels[2] = get_model()\n#models[3] = get_model()\n#models[4] = get_model()\n#models[0].summary()","metadata":{"papermill":{"duration":2.68022,"end_time":"2021-09-21T16:13:19.244138","exception":false,"start_time":"2021-09-21T16:13:16.563918","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習\ndef learning(key, model):\n\n    ## コンパイル\n    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n    model.compile(optimizer=Adam(decay=0.1), loss='binary_crossentropy', metrics=['binary_accuracy'])\n\n    ## 学習実施\n    ### アーリーストッピング設定\n    callback = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss', \n        patience=30\n    )\n    ### モデル保存設定\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        '/tmp/checkpoint_' + str(key), \n        monitor='val_binary_accuracy', \n        save_best_only=True   # val_binary_accuracy が最良のものを保存する設定\n    )\n    ### フィッティング\n    return model.fit(\n        train_ds,\n        validation_data=val_ds, \n        epochs=epochs, \n        callbacks=[callback, checkpoint]\n    )","metadata":{"papermill":{"duration":1514.111639,"end_time":"2021-09-21T16:38:33.414121","exception":false,"start_time":"2021-09-21T16:13:19.302482","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習実施\nresults = {}\nfor key, model in models.items():\n    print('=== model-' + str(key) + ' fiting ===')\n    results[key] = learning(key, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習概要見える化\nresult = results[0]\nhis_range = len(result.history['loss'])\n\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(range(1, his_range+1), result.history['binary_accuracy'], label=\"training\")\nplt.plot(range(1, his_range+1), result.history['val_binary_accuracy'], label=\"validation\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(range(1, his_range+1), result.history['loss'], label=\"training\")\nplt.plot(range(1, his_range+1), result.history['val_loss'], label=\"validation\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"papermill":{"duration":0.628198,"end_time":"2021-09-21T16:38:34.323009","exception":false,"start_time":"2021-09-21T16:38:33.694811","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MAKE submission.csv","metadata":{"papermill":{"duration":0.281886,"end_time":"2021-09-21T16:38:34.886955","exception":false,"start_time":"2021-09-21T16:38:34.605069","status":"completed"},"tags":[]}},{"cell_type":"code","source":"! ls plates/test/ | head ","metadata":{"papermill":{"duration":1.099559,"end_time":"2021-09-21T16:38:36.27007","exception":false,"start_time":"2021-09-21T16:38:35.170511","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# テストジェネレイター\ndef create_test_generator(l):\n    test_datagen = ImageDataGenerator()\n    return test_datagen.flow_from_directory(  \n        'data_test/plates/test',\n        classes=[str(l)],\n        target_size = image_size,\n        batch_size = 100,\n        shuffle = False,        \n        class_mode = None)  ","metadata":{"papermill":{"duration":0.293107,"end_time":"2021-09-21T16:38:36.846012","exception":false,"start_time":"2021-09-21T16:38:36.552905","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# テストジェネレイター生成\ntest_generators = {}\nfor l in crop_size_test_list:\n    test_generators[str(l)] = create_test_generator(l)","metadata":{"papermill":{"duration":0.60401,"end_time":"2021-09-21T16:38:37.730003","exception":false,"start_time":"2021-09-21T16:38:37.125993","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ナイーブテスト_1\n\n## 画像の読み込み\n#img = Image.open('data_test/plates/test/0028.jpg')\n#img = img.resize(image_size)\n#plt.imshow(img)\n\n## 予測\n#img = np.array(img)\n#model.predict([img[None,...]])","metadata":{"papermill":{"duration":0.288242,"end_time":"2021-09-21T16:38:38.299303","exception":false,"start_time":"2021-09-21T16:38:38.011061","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ナイーブテスト_2\nmodel = models[0]\n\n## 順番リセット\ntest_generator = test_generators[str(crop_size_test_list[0])]\ntest_generator.reset()\n\n## 精度感目視チェック  \nfor d in test_generator:\n    for i in range(30):\n        print(model.predict([d[i][None,...]]))\n        plt.imshow(d[i].astype(np.uint8))\n        plt.show()\n    break","metadata":{"papermill":{"duration":14.626759,"end_time":"2021-09-21T16:38:53.205256","exception":false,"start_time":"2021-09-21T16:38:38.578497","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 予測\npredicts = {}\nfor key, model in models.items():\n    for key_gen, test_generator in test_generators.items():\n        # 順番リセット\n        test_generator.reset()\n        # 予測\n        predicts['model:' + str(key) + ' - inputsize:' + str(key_gen)] = pd.Series(\n            np.ravel( # 一次元化\n                model.predict_generator(\n                    test_generator, \n                    steps = len(test_generator.filenames)\n                )\n            )\n        )","metadata":{"papermill":{"duration":218.258955,"end_time":"2021-09-21T16:42:31.845254","exception":false,"start_time":"2021-09-21T16:38:53.586299","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicts_df = pd.DataFrame(predicts)\npredicts_df.head(30)","metadata":{"papermill":{"duration":0.42031,"end_time":"2021-09-21T16:42:32.644747","exception":false,"start_time":"2021-09-21T16:42:32.224437","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/platesv2/sample_submission.csv')","metadata":{"papermill":{"duration":0.405821,"end_time":"2021-09-21T16:42:33.433022","exception":false,"start_time":"2021-09-21T16:42:33.027201","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = lambda x: 'dirty' if x > 0.5 else 'cleaned'\nsub_df['label'] = pd.DataFrame(\n    np.mean(\n        predicts_df, \n        axis=1\n    )\n)\nsub_df['label'] = sub_df['label'].apply(f)\nsub_df.head(30)","metadata":{"papermill":{"duration":0.420031,"end_time":"2021-09-21T16:42:34.225231","exception":false,"start_time":"2021-09-21T16:42:33.8052","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['label'].value_counts()","metadata":{"papermill":{"duration":0.392333,"end_time":"2021-09-21T16:42:35.02016","exception":false,"start_time":"2021-09-21T16:42:34.627827","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.388471,"end_time":"2021-09-21T16:42:35.808804","exception":false,"start_time":"2021-09-21T16:42:35.420333","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}